{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksDSiZQIr4SU"
   },
   "source": [
    "# CS 505 Homework 03:  N-Gram Modelling\n",
    "\n",
    "#### Due Monday  10/9 at midnight (1 minute after 11:59 pm) in Gradescope (with a grace period of 6 hours)\n",
    "#### You may submit the homework up to 24 hours late (with the same grace period) for a penalty of 10%.\n",
    "\n",
    "All homeworks will be scored with a maximum of 100 points; point values are given\n",
    "for individual problems, and if parts of problems do not have point values given, they\n",
    "will be counted equally toward the total for that problem.\n",
    "\n",
    "Note: I strongly recommend you work in **Google Colab** (the free version) to complete homeworks in this class; in addition to (probably) being faster than your laptop, all the necessary libraries will already be available to you, and you don't have to hassle with <code>conda</code>, <code>pip</code>, etc. and resolving problems when the install doesn't work. But it is up to you!   You should go through the necessary tutorials listed on the web site concerning Colab and storing files on a Google Drive. And of course, Dr. Google is always ready to help you resolve your problems.\n",
    "\n",
    "I will post a  \"walk-through\" video ASAP on my <a href=\"https://www.youtube.com/channel/UCfSqNB0yh99yuG4p4nzjPOA\">Youtube Channel</a>.\n",
    "\n",
    "#### Submission Instructions\n",
    "\n",
    "You must complete the homework by editing <b>this notebook</b> and submitting the following two files in Gradescope by the due date and time:\n",
    "\n",
    "  - A file <code>HW03.ipynb</code> (be sure to select <code>Kernel -> Restart and Run All</code> before you submit, to make sure everything works); and\n",
    "  - A file <code>HW03.pdf</code> created from the previous.\n",
    "  \n",
    "  For best results obtaining a clean PDF file on the Mac, select <code>File -> Print Review</code> from the Jupyter window, then choose <code>File-> Print</code> in your browser and then <code>Save as PDF</code>.  Something  similar should be possible on a Windows machine -- just make sure it is readable and no cell contents have been cut off. Make it easy to grade!\n",
    "  \n",
    "The date and time of your submission is the last file you submitted, so if your IPYNB file is submitted on time, but your PDF is late, then your submission is late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF9ENg8mr4SV"
   },
   "source": [
    "## Collaborators (5 pts)\n",
    "\n",
    "Describe briefly but precisely\n",
    "\n",
    "1. Any persons you discussed this homework with and the nature of the discussion;\n",
    "2. Any online resources you consulted and what information you got from those resources; and\n",
    "3. Any AI agents (such as chatGPT or CoPilot) or other applications you used to complete the homework, and the nature of the help you received.\n",
    "\n",
    "A few brief sentences is all that I am looking for here.\n",
    "\n",
    "I discussed the homework with Vineet Raju, Dominic Maglione, and Phillip Tran. I used Stack Overflow for minor debugging. I used chatGPT to debug potential issues with my code, but did not implement any of its suggestions since it was incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2384,
     "status": "ok",
     "timestamp": 1696168125603,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "hDTkaKtMr4SV",
    "outputId": "a84c3ffc-edc4-4d1f-8205-bca070e6007c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import shuffle, seed, choice\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# First time you will need to download the corpus:\n",
    "# Run the following and download the book collection\n",
    "\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS569hEdr4SX"
   },
   "source": [
    "## Problem One:  Bag of N-Grams\n",
    "\n",
    "A BOW is a language modelling technique (also called a Term Frequency Vector) which creates a frequency distribution for a set of tokens -- or unigrams!\n",
    "Extending this idea a bit, we can also create a Bag of N-Grams, which is a frequency distribution for\n",
    "a set of N-grams for some N. If we divide the frequency by the number of N-grams, we have a probability distribution, such as we showed for the exciting text about John and Mary in Lecture 5.\n",
    "\n",
    "For this homework, we are going to create such Bag of N-Gram models for N = 1, 2, 3, & 4, for the sentences\n",
    "in `brown.sents()`.  We will evaluate them using a test set, and then in the second part of the\n",
    "homework, we shall use them to generate sentences.\n",
    "\n",
    "\n",
    "**Note 1:**  We do not want to do the same low-level transformations in this project\n",
    "as we did in HW 02. We will keep the capitalization, punctuation, and\n",
    "words in all their various forms.  There are some strange things in `brown.sents()`, such as double semicolons, and bad sentence segmentation, but we will assume\n",
    "the processing of the texts into `brown.sents()` was consistent, and we will see what\n",
    "our model makes of this data.\n",
    "\n",
    "**Note 2:** Since `brown.sents()` contains punctuation marks as well as words, we shall use the term **tokens**\n",
    "for the strings stored in the sentence lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPXRVbWBr4SX"
   },
   "source": [
    "### Part A: Randomize the list of sentences and split into training and testing sets\n",
    "\n",
    "We will use  `brown.sents()` (a list of list of tokens) as the basis of our N-gram models.\n",
    "The list `brown.words()` is simply the concatenation of all these lists of tokens.\n",
    "\n",
    "We will shuffle the list into a random order, but using a seed value so that the order of the random\n",
    "shuffle is the same each time.\n",
    "\n",
    "1. Read about `numpy.random.seed` and `numpy.random.shuffle`.\n",
    "\n",
    "2. Set the seed to `0` and shuffle the list: you can't shuffle `brown.sents()` and because `numpy.random.shuffle` modifies the list **in place**, to avoid reshuffling:\n",
    "<ul>\n",
    "    <li> Convert <b>brown.sents()</b> to a list and assign to a new variable <b>sentences</b> and then\n",
    "    <li> <b>Copy sentences</b> to a new variable <b>shuffled_sentences</b> and then\n",
    "    <li> Shuffle that list.\n",
    "</ul>\n",
    "\n",
    "In this way, you will have the original list, and a randomized list, but because of `seed(0)` it will be in the same order every time you run your code (and when we grade it).\n",
    "\n",
    "3. Then split  `shuffled_sentences` into sets `training_sents` (first 99.9% of the sentences) and `testing_sents` (last 0.1%).\n",
    "\n",
    "4. Print out the length of the training and testing sets.\n",
    "\n",
    "5. Print out the first sentence in each of these sets.  \n",
    "\n",
    "In 4 and 5, label the outputs so we know which is which. (Always make outputs easy\n",
    "to understand!)\n",
    "\n",
    "NOTE: The terms \"training set\" and \"testing set\" are very standard, even though we store these in lists (it is\n",
    "possible that there are duplicate sentences).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9710,
     "status": "ok",
     "timestamp": 1696168135310,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "CzhBF3C-r4SY",
    "outputId": "094225f0-95d9-49f2-e81b-ded4a7ce23d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training set: 57282.\n",
      "Length of testing set: 58.\n",
      "Start of training set:\n",
      "['Muscle', 'weakness', 'did', 'not', 'improve', ',', 'and', 'the', 'patient', 'needed', 'first', 'a', 'cane', ',', 'then', 'crutches', '.']\n",
      "Start of testing set:\n",
      "['It', 'is', 'at', 'least', 'as', 'important', 'as', 'the', 'more', 'dramatic', 'attempts', 'to', 'break', 'down', 'barriers', 'of', 'inequality', 'in', 'the', 'South', '.']\n"
     ]
    }
   ],
   "source": [
    "# First, shuffle the set of sentences\n",
    "\n",
    "seed(0)\n",
    "\n",
    "# your code here\n",
    "sentences = list(brown.sents())\n",
    "shuffled_sentences = sentences.copy()\n",
    "shuffle(shuffled_sentences)\n",
    "\n",
    "train_end_idx = int(len(shuffled_sentences) * 0.999)\n",
    "training_sents = shuffled_sentences[:train_end_idx]\n",
    "testing_sents = shuffled_sentences[train_end_idx:]\n",
    "\n",
    "print(f\"Length training set: {len(training_sents)}.\")\n",
    "print(f\"Length of testing set: {len(testing_sents)}.\")\n",
    "\n",
    "print(f\"Start of training set:\\n{training_sents[0]}\")\n",
    "print(f\"Start of testing set:\\n{testing_sents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE83MqiTr4SY"
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now, you must add the beginning `<s>` and ending `</s>` markers to each sentence in both the\n",
    "training and testing lists.   Do not make any other changes\n",
    "to the sentences -- you will see that punctuation has been left in, such as periods at the end\n",
    "of sentences. Again, we will see what our models make of this data set.\n",
    "\n",
    "Print out the first sentence in each of the training and testing sets to check that all is well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1696168136574,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "2ill0k35r4SY",
    "outputId": "f5491ba8-1ae7-45d5-ffcc-ee18fe0c7919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training set:\n",
      "['<s>', 'Muscle', 'weakness', 'did', 'not', 'improve', ',', 'and', 'the', 'patient', 'needed', 'first', 'a', 'cane', ',', 'then', 'crutches', '.', '</s>']\n",
      "\n",
      "Start of testing set:\n",
      "['<s>', 'It', 'is', 'at', 'least', 'as', 'important', 'as', 'the', 'more', 'dramatic', 'attempts', 'to', 'break', 'down', 'barriers', 'of', 'inequality', 'in', 'the', 'South', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# put `<s>` at beginning and `</s>` at end of all sentences.\n",
    "\n",
    "def bracket_sentence(sent):\n",
    "  return [\"<s>\"] + sent + [\"</s>\"]   # your code here\n",
    "\n",
    "\n",
    "# your code here\n",
    "training_sents = list(map(bracket_sentence, training_sents))\n",
    "testing_sents = list(map(bracket_sentence, testing_sents))\n",
    "\n",
    "print(f\"Start of training set:\\n{training_sents[0]}\")\n",
    "print()\n",
    "print(f\"Start of testing set:\\n{testing_sents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AW1z9jbOr4SZ"
   },
   "source": [
    "###  Part C\n",
    "\n",
    "Complete the following template for a function to extract N-grams from one sentence, and test\n",
    "it for N = 1,2,3,4 for the first sentences in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168136574,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "khQLlZ-pr4Sa",
    "outputId": "a7640c76-fb07-4422-d0a7-03b34e02557b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('Muscle',), ('weakness',), ('did',), ('not',), ('improve',), (',',), ('and',), ('the',), ('patient',), ('needed',), ('first',), ('a',), ('cane',), (',',), ('then',), ('crutches',), ('.',), ('</s>',)]\n",
      "[('<s>', 'Muscle'), ('Muscle', 'weakness'), ('weakness', 'did'), ('did', 'not'), ('not', 'improve'), ('improve', ','), (',', 'and'), ('and', 'the'), ('the', 'patient'), ('patient', 'needed'), ('needed', 'first'), ('first', 'a'), ('a', 'cane'), ('cane', ','), (',', 'then'), ('then', 'crutches'), ('crutches', '.'), ('.', '</s>')]\n",
      "[('<s>', 'Muscle', 'weakness'), ('Muscle', 'weakness', 'did'), ('weakness', 'did', 'not'), ('did', 'not', 'improve'), ('not', 'improve', ','), ('improve', ',', 'and'), (',', 'and', 'the'), ('and', 'the', 'patient'), ('the', 'patient', 'needed'), ('patient', 'needed', 'first'), ('needed', 'first', 'a'), ('first', 'a', 'cane'), ('a', 'cane', ','), ('cane', ',', 'then'), (',', 'then', 'crutches'), ('then', 'crutches', '.'), ('crutches', '.', '</s>')]\n",
      "[('<s>', 'Muscle', 'weakness', 'did'), ('Muscle', 'weakness', 'did', 'not'), ('weakness', 'did', 'not', 'improve'), ('did', 'not', 'improve', ','), ('not', 'improve', ',', 'and'), ('improve', ',', 'and', 'the'), (',', 'and', 'the', 'patient'), ('and', 'the', 'patient', 'needed'), ('the', 'patient', 'needed', 'first'), ('patient', 'needed', 'first', 'a'), ('needed', 'first', 'a', 'cane'), ('first', 'a', 'cane', ','), ('a', 'cane', ',', 'then'), ('cane', ',', 'then', 'crutches'), (',', 'then', 'crutches', '.'), ('then', 'crutches', '.', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "# Return a list of the N-grams for all sentences s\n",
    "\n",
    "# Store all N-grams as tuples, so that a unigram is (w,), a bigram is (w1,w2), etc.\n",
    "\n",
    "def get_Ngrams_for_sentence(N,s):\n",
    "  return list(tuple(s[i:i+N]) for i in range(len(s) - N + 1))    # your code here\n",
    "\n",
    "\n",
    "# your code here\n",
    "first_train_sentence = training_sents[0]\n",
    "unigram = get_Ngrams_for_sentence(1, first_train_sentence)\n",
    "bigram = get_Ngrams_for_sentence(2, first_train_sentence)\n",
    "trigram = get_Ngrams_for_sentence(3, first_train_sentence)\n",
    "four_gram = get_Ngrams_for_sentence(4, first_train_sentence)\n",
    "\n",
    "print(unigram)\n",
    "print(bigram)\n",
    "print(trigram)\n",
    "print(four_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxQhM9zir4Sa"
   },
   "source": [
    "###  Part D\n",
    "\n",
    "Now create lists of N-grams for all the sentences in your training set (NOT the testing set).\n",
    "Complete the following template to assign these to the given list.\n",
    "\n",
    "Print out the number of N-grams, and the first 5 N-grams in each list for N = 1, 2, 3, 4.\n",
    "\n",
    "Note that this number is the number of occurrences of N-grams, which may not be unique in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4013,
     "status": "ok",
     "timestamp": 1696168140584,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "v36VKkuAr4Sa",
    "outputId": "89648bde-53fc-45e4-ff92-f84a103d0ea0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1274667 N-grams in Ngrams[1] and the first 5 are:\n",
      "[('<s>',), ('Muscle',), ('weakness',), ('did',), ('not',)]\n",
      "\n",
      "There are 1217385 N-grams in Ngrams[2] and the first 5 are:\n",
      "[('<s>', 'Muscle'), ('Muscle', 'weakness'), ('weakness', 'did'), ('did', 'not'), ('not', 'improve')]\n",
      "\n",
      "There are 1160103 N-grams in Ngrams[3] and the first 5 are:\n",
      "[('<s>', 'Muscle', 'weakness'), ('Muscle', 'weakness', 'did'), ('weakness', 'did', 'not'), ('did', 'not', 'improve'), ('not', 'improve', ',')]\n",
      "\n",
      "There are 1102821 N-grams in Ngrams[4] and the first 5 are:\n",
      "[('<s>', 'Muscle', 'weakness', 'did'), ('Muscle', 'weakness', 'did', 'not'), ('weakness', 'did', 'not', 'improve'), ('did', 'not', 'improve', ','), ('not', 'improve', ',', 'and')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ngrams = [None]*5    # first slot is empty, then Ngram[1] will hold unigrams, Ngram[2] will hold bigrams, etc.\n",
    "\n",
    "\n",
    "# your code here\n",
    "for n in range(1, 5):\n",
    "  Ngrams[n] = []\n",
    "  for s in training_sents:\n",
    "    Ngrams[n].extend(get_Ngrams_for_sentence(n, s))\n",
    "\n",
    "\n",
    "for n in range(1, 5):\n",
    "  print(f\"There are {len(Ngrams[n])} N-grams in Ngrams[{n}] and the first 5 are:\")\n",
    "  print(Ngrams[n][:5])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPALztwQr4Sb"
   },
   "source": [
    "### Part E\n",
    "\n",
    "We will now create a probability distribution for each of the Ngram collections. Note carefully\n",
    "that you must divide the frequency of each N-gram by the number of occurrences of N-grams, not\n",
    "the number of unique N-grams.\n",
    "\n",
    "Note that we have set the probability of the unigram `<s>` to 1.0. This is because we are\n",
    "interested in calculating the probability of sentences, which *always* begin with the token `'<s>'`.\n",
    "\n",
    "Complete the following template and then\n",
    "\n",
    "1. Print out the total number of N-grams in each dictionary (they should be a bit smaller than the totals in the last part - why?).\n",
    "2. Test your code by printing out the probability of the following Ngrams to 8 digits of precision:\n",
    "\n",
    "        ('to',)           \n",
    "        ('to','the')            \n",
    "        ('to','the','house')              \n",
    "        ('to','the','house','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3862,
     "status": "ok",
     "timestamp": 1696168144441,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "q_v25wrJr4Sb",
    "outputId": "d4441b1c-cdce-4186-c385-73eadb6f53c1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Probability of ('<s>',) is 1.0.\n",
      "\n",
      "The Probability of ('to',) is 0.02017703.\n",
      "\n",
      "The Probability of ('to','the') is 0.00281341.\n",
      "\n",
      "The Probability of ('to','the','house') is 9.48e-06.\n",
      "\n",
      "The Probability of ('to','the','house','.')  is 2.72e-06.\n"
     ]
    }
   ],
   "source": [
    "# Create a defaultdict with the frequency distribution for the training set for a given N.\n",
    "def get_Ngram_distribution(N, Ngrams):\n",
    "  # your code here\n",
    "  Ngram_dist = defaultdict(int)\n",
    "\n",
    "  for gram in Ngrams[N]:\n",
    "    Ngram_dist[gram] += 1\n",
    "\n",
    "  for key in Ngram_dist.keys():\n",
    "    Ngram_dist[key] /= len(Ngrams[N])\n",
    "\n",
    "  return Ngram_dist\n",
    "\n",
    "\n",
    "# your code here\n",
    "# now create for N = 1,2,3,4\n",
    "Ngram_distribution = [None]*5\n",
    "\n",
    "for n in range(1, 5):\n",
    "  Ngram_distribution[n] = get_Ngram_distribution(n, Ngrams)\n",
    "\n",
    "# Since all sentences will start with <s>, its probability should be 1.0\n",
    "\n",
    "Ngram_distribution[1][('<s>',)] = 1.0\n",
    "\n",
    "# tests\n",
    "\n",
    "print(f\"\\nThe Probability of ('<s>',) is {np.around(Ngram_distribution[1][('<s>',)],8)}.\")\n",
    "print(f\"\\nThe Probability of ('to',) is {np.around(Ngram_distribution[1][('to',)],8)}.\")\n",
    "print(f\"\\nThe Probability of ('to','the') is {np.around(Ngram_distribution[2][('to','the')],8)}.\")\n",
    "print(f\"\\nThe Probability of ('to','the','house') is {np.around(Ngram_distribution[3][('to','the','house')],8)}.\")\n",
    "print(f\"\\nThe Probability of ('to','the','house','.')  is {np.around(Ngram_distribution[4][('to','the','house','.') ],8)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNcFbZW0r4Sb"
   },
   "source": [
    "## Probability and Perplexity\n",
    "\n",
    "Now we will calculate the probability and the perplexity of sequences\n",
    "of tokens, using the principle of \"Stupid Backoff\" as explained\n",
    "in the paper:\n",
    "\n",
    "https://aclanthology.org/D07-1090.pdf\n",
    "\n",
    "and explicated in this StackOverflow post:\n",
    "\n",
    "https://stackoverflow.com/questions/16383194/stupid-backoff-implementation-clarification\n",
    "\n",
    "Before describing \"Stupid Backoff,\" let us consider the naive way to\n",
    "calculate the probability of a sequence of tokens which starts with `<s>`.\n",
    "\n",
    "#### A simple and naive way to calculate probabilities of sequences of tokens\n",
    "\n",
    "Suppose we have a quadrigram model (N = 4), we have a sequence of tokens\n",
    "\n",
    "$$w_1, w_2, \\cdots, w_n,$$   \n",
    "\n",
    "Assume we have calculated all the N-gram\n",
    "probabilities in  `Ngram_distribution[N]` for N = 1,2,3,4.  \n",
    "\n",
    "\n",
    "We will calculate the probability of each successive token $w_i$ in as much left context as we have, up to 3 (the\n",
    "last token in the 4-gram being $w_i$).\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "        p_1 &= \\text{Ngram_distribution[1][($w_1$,)]}    \\\\   \n",
    "        p_2 &=   \\text{Ngram_distribution[2][$( w_1,w_2)$]}\\ / \\ \\text{Ngram_distribution[1][$( w_1,)$]}    \\\\              p_3 &=   \\text{Ngram_distribution[3][$( w_1,w_2,w_3)$]}\\ / \\  \\text{Ngram_distribution[2][$(\\text{'<s>'}, w_1,w_2)$]}   \\\\      \n",
    "        p_4 &=   \\text{Ngram_distribution[4][$( w_1,w_2,w_3,w_4)$]}\\ / \\  \\text{Ngram_distribution[3][$(\\text{'<s>'}, w_1,w_2,w_3)$]}   \\\\        \n",
    "            &\\ldots                             \\\\\n",
    "        p_i &=   \\text{Ngram_distribution[4][$(w_{i-3}, w_{i-2}, w_{i-1}, w_i)$]}\\ /\\  \\text{Ngram_distribution[3][$(w_{i-3}, w_{i-2}, w_{i-1})$]}   \\\\        \n",
    "                    &\\ldots                            \\\\\n",
    "        p_n &=  \\text{Ngram_distribution[4][$(w_{n-3}, w_{n-2}, w_{n-1}, w_n)$]}\\ /\\  \\text{Ngram_distribution[3][$(w_{n-3}, w_{n-2}, w_{n-1})$]}     \\\\        \n",
    "  \\end{aligned}$$\n",
    "  \n",
    "Note that if $w_1$ is `<s>`, then $p_1=1.0$.\n",
    "    \n",
    "Finally, let\n",
    "\n",
    "$$P(\\text{'<s>'}, w_1, w_2, \\cdots, w_n)\\ =\\ p_1\\ast p_2\\ast\\cdots\\ast p_n.$$\n",
    "\n",
    "One messy detail is dealing with the possibility of 0 counts (if that is possible); thus,\n",
    "if the numerator in the above expressions is 0, then the entire product is 0 (you want to avoid\n",
    "a divide by 0 error in the denominator).\n",
    "\n",
    "#### What could possibly go wrong?\n",
    "\n",
    "Well, if our sentence is from our training set, nothing!  All the probabilities will\n",
    "have been calculated for all the possible N-grams.\n",
    "\n",
    "However, when we have a separate\n",
    "training set, we have to account for the fact that **some N-grams (and even\n",
    "some tokens) may occur in the testing set which do not occur in the training set,\n",
    "and so their probability will be 0.**  However, we want to make the best estimate\n",
    "of the probability we can!\n",
    "\n",
    "There are various solutions, which we discussed in lectures 5 and 6, but the simplest\n",
    "(and very effective for large data sets) is \"Stupid Backoff,\" recursively defined as follows\n",
    "for bigrams, trigrams, and quadrigrams, and **using the probability calculations shown above.**\n",
    "\n",
    "    PN_stupid_backoff(w1) = p1   as defined above           # if this is not 0, else:\n",
    "                          = (frequency of w1 in whole corpus / number of tokens in whole corpus)\n",
    "              \n",
    "    PN_stupid_backoff(w1, w2) = p2   as defined above         # if this is not 0, else:\n",
    "                              = 0.4 * P_stupid_backoff(w2)    # recursive, use previous definition\n",
    "\n",
    "    PN_stupid_backoff(w1, w2, w3) = p3   as defined above           # if this is not 0, else:\n",
    "                                  = 0.4 * P_stupid_backoff(w2, w3)  # recursive, use definition above\n",
    "\n",
    "                       \n",
    "    PN_stupid_backoff(w1, w2, w3, w4) = p4  as defined above                 # if this is not 0, else:\n",
    "                                      = 0.4 * P_stupid_backoff(w2, w3, w4)   # recursive, previous definition\n",
    "\n",
    "This accounts for how to backoff when trying to find the probability of some $w_i$ in a left context\n",
    "of 1, 2, or 3 tokens.\n",
    "\n",
    "Then we use these calculations instead of $p_1$, $p_2$ as in the previous algorithm, for trigrams\n",
    "it would be:\n",
    "\n",
    "     P_stupid_backoff(w1, w2, w3, w4, ..., wn) =   PN_stupid_backoff(w1)\n",
    "                                                 * PN_stupid_backoff(w1, w2)\n",
    "                                                 * PN_stupid_backoff(w1, w2, w3)\n",
    "                                                 * PN_stupid_backoff(w2, w3, w4)\n",
    "                                                 ...\n",
    "                                                 * PN_stupid_backoff(w(n-2), w(n-1), wn)\n",
    "\n",
    "The \"discount factor\"\n",
    "0.4 was proposed by the originators of the method, and seems to work well in practice.\n",
    "\n",
    "This calculation is unnecessary in generative models, since then we will train on the entire\n",
    "corpus, and only use available N-grams to produce sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHJ1c0mdr4Sc"
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "Now we will calculate the probability of a sequence of tokens. We will warm up by considering\n",
    "the simple case, and then consider the more complex case, where\n",
    "\"stupid backoff\" will be used.\n",
    "\n",
    "### Part A\n",
    "\n",
    "For this part, complete the following template to create a function which will\n",
    "calculate the probability of a sequence of tokens.\n",
    "\n",
    "**Since you may want to use this in the stupid backoff version, you should make sure that if the\n",
    "numerator in the conditional probability calculation is 0, immediately return 0,\n",
    "so that there is no possibility of divide by 0 in the denominator.**\n",
    "\n",
    "Tests are provided following the cell in which you will write your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696168144441,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "SPCWQjpzr4Sc"
   },
   "outputs": [],
   "source": [
    "# Probability of a list of tokens using N-grams\n",
    "# W a list of tokens\n",
    "\n",
    "# Calculate the probability of the last token in W, as we did in the calculation of p1, p2, etc. above\n",
    "# check numerator: if it is 0, return 0 immediately and do not do the division (to avoid possible\n",
    "# division by 0)\n",
    "\n",
    "# N == len(W)\n",
    "\n",
    "def PN(N,W):\n",
    "  # your code here\n",
    "  # precondition: N == len(W)\n",
    "\n",
    "  numerator = Ngram_distribution[N].get(W, 0)\n",
    "\n",
    "  if Ngram_distribution[N-1]:\n",
    "    denominator = Ngram_distribution[N-1].get(W[:-1], 0)\n",
    "  else:\n",
    "    # unigram case\n",
    "    return numerator\n",
    "\n",
    "  # prevent division by 0\n",
    "  if denominator == 0:\n",
    "    return 0\n",
    "\n",
    "  return numerator / denominator\n",
    "\n",
    "\n",
    "# Now calculate for a whole sequence: use PN(..) for bigram, trigram, etc. up to size of\n",
    "# model, then slide PN(...) across the sequence, as shown above.\n",
    "\n",
    "def P(N,W):\n",
    "  # your code here\n",
    "  proba = 1.0\n",
    "\n",
    "  for i in range(2, N):\n",
    "    proba *= PN(i, W[:i])\n",
    "\n",
    "  for i in range(len(W) - N + 1):\n",
    "    proba *= PN(N, W[i:i+N])\n",
    "\n",
    "  return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93lVOImBr4Sc"
   },
   "source": [
    "The following are tests to make sure your code is working properly. The values printed\n",
    "should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168144441,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "lRzxID7Ur4Sc",
    "outputId": "e97acbb3-b8ea-4e8b-bb26-c5ffc872064e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= 0.002346012148991486\n",
      "   0.002346012148991486\n",
      "b = 0.000351478118528877\n",
      "   0.000351478118528877\n",
      "c= 0.39264499316157175\n",
      "   0.39264499316157175\n",
      "d= 1.0470533150975245\n",
      "   1.0470533150975245\n",
      "\n",
      "a*b*c*d:   3.389982137368031e-07\n",
      "P(2,...):  3.389982137368031e-07\n"
     ]
    }
   ],
   "source": [
    "#  Sentence:  He frowned.\n",
    "#  Using a bigram model\n",
    "\n",
    "a = Ngram_distribution[2][('<s>','He')]\n",
    "b = Ngram_distribution[2][('He','frowned')] / Ngram_distribution[1][('He',)]\n",
    "c = Ngram_distribution[2][('frowned','.')] / Ngram_distribution[1][('frowned',)]\n",
    "d = Ngram_distribution[2][('.','</s>')] / Ngram_distribution[1][('.',)]\n",
    "\n",
    "\n",
    "print('a=', a)\n",
    "print('  ', PN(2,('<s>','He')))\n",
    "print('b =', b)\n",
    "print('  ', PN(2,('He','frowned')))\n",
    "print('c=', c)\n",
    "print('  ', PN(2,('frowned','.')))\n",
    "print('d=', d)\n",
    "print('  ', PN(2,('.','</s>')))\n",
    "\n",
    "print('\\na*b*c*d:  ',a*b*c*d)\n",
    "print('P(2,...): ', P(2,('<s>','He','frowned','.','</s>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168144441,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "gO3nGej7r4Sd",
    "outputId": "5db4a500-63de-48e3-8243-0f0b46fbea88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a*b*c*d:   9.492186072583041e-07\n",
      "P(3,...):  9.492186072583041e-07\n"
     ]
    }
   ],
   "source": [
    "#  Sentence:  He frowned.\n",
    "#  Using a trigram model\n",
    "\n",
    "a = Ngram_distribution[2][('<s>','He')]\n",
    "b = Ngram_distribution[3][('<s>','He','frowned')] / Ngram_distribution[2][('<s>','He',)]\n",
    "c = Ngram_distribution[3][('He','frowned','.')] / Ngram_distribution[2][('He','frowned',)]\n",
    "d = Ngram_distribution[3][('frowned','.','</s>')] / Ngram_distribution[2][('frowned','.',)]\n",
    "\n",
    "print('a*b*c*d:  ',a*b*c*d)\n",
    "print('P(3,...): ', P(3,('<s>','He','frowned','.','</s>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696168144441,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "5Y3q2BeEr4Sd",
    "outputId": "344bf0e9-7875-41a8-94be-1ad44761d630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a*b*c*d:   9.538640808692934e-07\n",
      "P(4,...):  9.538640808692934e-07\n"
     ]
    }
   ],
   "source": [
    "#  Sentence:  He frowned.\n",
    "#  Using a quadrigram model\n",
    "\n",
    "a = Ngram_distribution[2][('<s>','He')]\n",
    "b = Ngram_distribution[3][('<s>','He','frowned')] / Ngram_distribution[2][('<s>','He',)]\n",
    "c = Ngram_distribution[4][('<s>','He','frowned','.')] / Ngram_distribution[3][('<s>','He','frowned',)]\n",
    "d = Ngram_distribution[4][('He','frowned','.','</s>')] / Ngram_distribution[3][('He','frowned','.',)]\n",
    "\n",
    "print('a*b*c*d:  ',a*b*c*d)\n",
    "print('P(4,...): ', P(4,('<s>','He','frowned','.','</s>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696168144442,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "U8r0qyIrr4Sd",
    "outputId": "bc6dc982-ef6e-4b09-dc2f-abba9768492f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= 0.001128648701930778 \n",
      "b= 0.0015274769289326804 \n",
      "c= 0.0 \n",
      "d1= 0 \n",
      "d2= 0 \n",
      "\n",
      "a*b*d*d1:   0.0\n",
      "P(3,...):  0.0\n"
     ]
    }
   ],
   "source": [
    "# Sentence:  I love NLP\n",
    "# using trigrams\n",
    "\n",
    "# This shows that you should test the numerator to see if it is 0, because then\n",
    "# you can return 0 immediately, and not have the possibility of division by 0,\n",
    "# which would occur in the cases d below (c is 0 but would not cause division by 0)\n",
    "\n",
    "a  = Ngram_distribution[2][('<s>','I')]\n",
    "b  = Ngram_distribution[3][('<s>','I','love')] / Ngram_distribution[2][('<s>','I',)]\n",
    "c  = Ngram_distribution[3][('I','love','NLP')] / Ngram_distribution[2][('I','love')]\n",
    "d1 = Ngram_distribution[3][('love','NLP','</s>')]\n",
    "d2 = Ngram_distribution[2][('love','NLP')]\n",
    "\n",
    "print('a=',a,'\\nb=',b,'\\nc=',c,'\\nd1=',d1,'\\nd2=',d2,'\\n')\n",
    "\n",
    "print('a*b*d*d1:  ',a*b*c*d1)\n",
    "print('P(3,...): ', P(3,('<s>','I','love','NLP','</s>')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyfufaIdr4Sd"
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now we will develop the probability for a sequence with the possibility that some N-grams, or\n",
    "even some tokens, are not in the training set. We will use the idea of \"stupid backoff\" explained\n",
    "in lecture.\n",
    "\n",
    "Complete the following template and verify that it passes all the tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5650,
     "status": "ok",
     "timestamp": 1696168150089,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Ko3nIvuur4Sd"
   },
   "outputs": [],
   "source": [
    "# Probability with stupid backoff\n",
    "# same as previous, but have to use recursive (or iterative) method instead of\n",
    "# calling Ngram_distribution directly\n",
    "\n",
    "# W a list of tokens\n",
    "\n",
    "# This returns backed-off probability for single N-gram\n",
    "# len(W) must be N, this will try whole N-gram, then last N-1 tokens, then N-2, etc. down to 1 token.\n",
    "\n",
    "# Assumes W is a tuple\n",
    "\n",
    "# calculate for a particular length N-gram\n",
    "# must have N == len(W)\n",
    "\n",
    "all_words = list(brown.words())\n",
    "\n",
    "\n",
    "def PN_with_stupid_backoff(N,W):\n",
    "  # your code here\n",
    "  proba = PN(N, W)\n",
    "\n",
    "  if proba > 0:\n",
    "    return proba\n",
    "\n",
    "  elif N == 1:\n",
    "    return all_words.count(W[0]) / len(all_words)\n",
    "\n",
    "  return 0.4 * PN_with_stupid_backoff(N-1,W[1:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note that for training set, this will be same as P(N,W) since all probabilities are non-zero\n",
    "\n",
    "# Really the same as P(N,W) except using the previous function, and no need to check for 0,\n",
    "# since it never returns 0 for a sequence using words from the corpus\n",
    "\n",
    "\n",
    "\n",
    "def P_stupid_backoff(N,W):\n",
    "  # your code here\n",
    "  proba = 1.0\n",
    "\n",
    "  for i in range(2, N):\n",
    "    proba *= PN_with_stupid_backoff(i, W[:i])\n",
    "\n",
    "  for i in range(len(W) - N + 1):\n",
    "    proba *= PN_with_stupid_backoff(N, W[i:i+N])\n",
    "\n",
    "  return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaMHsSDpr4Se"
   },
   "source": [
    "The following are tests to make sure your code is working properly. The values printed\n",
    "should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1696168150293,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Cm9Xn5NLr4Se",
    "outputId": "0377ba3e-aed9-4802-a48a-c3661931ad32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'grandstand' is in testing set but not in the training set\n",
    "# This uses bigrams\n",
    "\n",
    "P(2,('<s>','where','is','the','grandstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6565,
     "status": "ok",
     "timestamp": 1696168156856,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "2UXCvcyQr4Se",
    "outputId": "2581bb81-b9b9-49c2-d464-4f166d18c6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 1.6428656505542618e-06 \n",
      "b = 0.006166391726133832 \n",
      "c = 0.08182229363508187 \n",
      "d2= 0.0 \n",
      "d1= 0 \n",
      "d = 8.611840246918683e-07 \n",
      "\n",
      "2.855359302895301e-16\n",
      "2.855359302895301e-16\n"
     ]
    }
   ],
   "source": [
    "a = PN(2,('<s>','where'))\n",
    "b = PN(2,('where','is'))\n",
    "c = PN(2,('is','the'))\n",
    "d2 = PN(2,('the','grandstand'))     # this is 0, so use less context\n",
    "d1 = PN(1,('grandstand'))           # this is 0, so use 0.4*d instead of d2\n",
    "d  = list(brown.words()).count('grandstand') / len(brown.words())\n",
    "\n",
    "print('a =',a,'\\nb =',b,'\\nc =',c,'\\nd2=',d2,'\\nd1=',d1,'\\nd =',d,'\\n')\n",
    "print(a*b*c*(0.4*d))\n",
    "print(P_stupid_backoff(2,('<s>','where','is','the','grandstand')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1696168156856,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Z7DRbyEbr4Se",
    "outputId": "4844392b-5fff-41c3-c033-0bd259ac8077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'grandstand' is in testing set but not in the training set\n",
    "# This uses trigrams\n",
    "\n",
    "P(3,('<s>','where','is','the','grandstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7792,
     "status": "ok",
     "timestamp": 1696168164646,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "kJLQ6KScr4Sf",
    "outputId": "fd54e71b-1c86-4f75-c071-00b6828822db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 1.6428656505542618e-06 \n",
      "b3= 0.0 \n",
      "b2= 0.006166391726133832 \n",
      "c = 0.4197506600707006 \n",
      "d3= 0.0 \n",
      "d2= 0.0 \n",
      "d1= 0 \n",
      "d = 8.611840246918683e-07 \n",
      "\n",
      "2.3436917228933544e-16\n",
      "2.3436917228933544e-16\n"
     ]
    }
   ],
   "source": [
    "a  = PN(2,('<s>','where'))               # <= this works\n",
    "b3 = PN(3,('<s>','where','is'))         # this is 0, so try less context\n",
    "b2 = PN(2,('where','is'))               # <= this works\n",
    "c  = PN(3,('where','is','the'))          # <= this works\n",
    "\n",
    "d3 = PN(3,('is','the','grandstand'))    # this is 0, so try less context\n",
    "d2 = PN(2,('the','grandstand'))         # this is 0, so try less context\n",
    "d1 = PN(1,('grandstand'))               # this is 0, so use probability in whole corpus\n",
    "d  = list(brown.words()).count('grandstand') / len(brown.words())     # <= this works\n",
    "\n",
    "print('a =',a,'\\nb3=',b3,'\\nb2=',b2,'\\nc =',c,'\\nd3=',d3,'\\nd2=',d2,'\\nd1=',d1,'\\nd =',d,'\\n')\n",
    "\n",
    "# every time we try less context, must multiply by 0.4, so we\n",
    "# use 0.4*b2 instead of b3 and 0.4*0.4*e instead of d3\n",
    "print(a*(0.4*b2)*c*(0.4*0.4*d))\n",
    "print(P_stupid_backoff(3,('<s>','where','is','the','grandstand')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6234,
     "status": "ok",
     "timestamp": 1696168170876,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "4bibv1yrr4Sf",
    "outputId": "65b2918a-a3b0-453d-dd3c-92b389979aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0.005372992110137713 \n",
      "b3= 0.0 \n",
      "b2= 0.0 \n",
      "b1= 0 \n",
      "b = 8.611840246918683e-07\n",
      "c3= 0 \n",
      "c2= 0 \n",
      "c1= 7.21757133431712e-05 \n",
      "d3= 0 \n",
      "d2= 0.01138101429453831 \n",
      "e3= 0.0 \n",
      "e2= 0.0011817757506744071 \n",
      "\n",
      "1.839836556015632e-20\n",
      "1.839836556015632e-20\n"
     ]
    }
   ],
   "source": [
    "a  = PN(2,('<s>','The'))                   #   <= this works\n",
    "\n",
    "b3 = PN(3,('<s>','The','grandstand'))      # this is 0, so try less context (smaller N)\n",
    "b2 = PN(2,('The','grandstand'))            # this is 0, so try less context\n",
    "b1 = PN(1,('grandstand',))                 # this is 0, so have to use frequency in whole corpus\n",
    "b  = list(brown.words()).count('grandstand') / len(brown.words())    #   <= this works\n",
    "\n",
    "c3 = PN(3,('The','grandstand','fell'))     # this is 0, so try less context\n",
    "c2 = PN(2,('grandstand','fell'))           # this is 0, so try less context\n",
    "c1 = PN(1,('fell',))                       # ok, this works\n",
    "\n",
    "d3 = PN(3,('grandstand','fell','down'))   # this is 0, so try less context\n",
    "d2 = PN(2,('fell','down'))                #   <= this works\n",
    "\n",
    "e3 = PN(3,('fell','down','</s>'))         # this is 0, so try less context\n",
    "e2 = PN(2,('down','</s>'))                #  <= this works\n",
    "\n",
    "# every time we tried a smaller N, we have to multiply by 0.4\n",
    "# so we use a, then 0.4*0.4*b0, then 0.4*0.4*c1, then 0.4*d2, then 0.4*e2e.\n",
    "\n",
    "print('a =',a,'\\nb3=',b3,'\\nb2=',b2,'\\nb1=',b1,'\\nb =',b)\n",
    "print('c3=',c3,'\\nc2=',c2,'\\nc1=',c1,'\\nd3=',d3,'\\nd2=',d2,'\\ne3=',e3,'\\ne2=',e2,'\\n')\n",
    "\n",
    "print(a * (0.4*0.4*b) * (0.4*0.4*c1) * (0.4*d2) * (0.4*e2) )\n",
    "print(P_stupid_backoff(3,('<s>','The','grandstand','fell','down','</s>')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5ghvuBQr4Sf"
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now we will implement the notion of *perplexity* as explained in lecture. Refer to\n",
    "the formula presented there to complete the following template, and verify\n",
    "that it passes all the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1696168170876,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "04zeOmAEr4Sf"
   },
   "outputs": [],
   "source": [
    "# Perplexity\n",
    "\n",
    "# We assume that W starts with <s>, may not end with </s>\n",
    "\n",
    "def PP(N,W):\n",
    "  # your code here\n",
    "  p = P_stupid_backoff(N, W)\n",
    "  if p == 0.0:\n",
    "    return 0.0\n",
    "  return p**( -1 / (len(W)-1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu-2R8cVr4Sf"
   },
   "source": [
    "If we know that no probabilities can be 0,  then P is same as P_stupid_backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1696168170876,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "k_OUt-sTr4Sg",
    "outputId": "3f25238f-2837-4827-ff14-0e5a91f6d702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.11603730316466"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(2,('<s>','The'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1696168170876,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "A88Y4x3xr4Sg",
    "outputId": "49137398-f155-4410-d38a-3c876ff6fc24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.11603730316466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2,('<s>','The'))**(-1/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "2xvZsspWr4Sg",
    "outputId": "58166f04-fec4-464b-87fd-a5bc20420f64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.11603730316466"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(2,('<s>','The'))**(-1/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "uXlDySwNr4Sg",
    "outputId": "5808da19-0750-4669-f147-b67fb7510938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308.91157551766736"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(2,('<s>','The','man','went'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "DM5_SOS1r4Sg",
    "outputId": "ff531642-265c-4844-dc24-9eba363e4037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308.91157551766736"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2,('<s>','The','man','went'))**(-1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "pbn0e5cDr4Sg",
    "outputId": "9f6a241e-bcdc-424a-e8cc-37864a1487c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308.91157551766736"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(2,('<s>','The','man','went'))**(-1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "e80Y0eMYr4Sg",
    "outputId": "a7f47bf1-b553-4c86-96e7-3a15e40dc6e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.03849995731908"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(2,('<s>','The','man','went','to','the', 'house','.','</s>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "smCUi84fr4Sh",
    "outputId": "42ac2ba9-4f33-4f9e-8a63-4a41aa8059b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.03849995731908"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(2,('<s>','The','man','went','to','the', 'house','.','</s>'))**(-1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168170877,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "fu875d2kr4Sh",
    "outputId": "efd67a60-6f0c-441c-cfc1-8f496da927fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.03849995731908"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(2,('<s>','The','man','went','to','the', 'house','.','</s>'))**(-1/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfgCnJgpr4Sh"
   },
   "source": [
    "When probabilities may be 0, we must use stupid backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1696168171084,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Qs9Xgg0Yr4Sh",
    "outputId": "6ca7440e-c29f-47a5-df59-c05b4fae716b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7692.8065013245405"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(2,('<s>','where','is','the','grandstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696168171085,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "mb_3Dm1Lr4Sh",
    "outputId": "60f27123-9105-42aa-d6c7-889ed40a8bea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7692.8065013245405"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(2,('<s>','where','is','the','grandstand'))**(-1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168171085,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "qxF03aMAr4Si",
    "outputId": "d608fb8a-78d9-458c-d620-a9091b614588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8082.112259400884"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(3,('<s>','where','is','the','grandstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696168171085,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "-fEGv0bcr4Si",
    "outputId": "e5e06ba0-5094-4842-8f95-cb4efa893500"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8082.112259400884"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(3,('<s>','where','is','the','grandstand'))**(-1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1696168171220,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "FJkEqN3Gr4Si",
    "outputId": "16f55114-ebdd-4af0-f270-6c75f39afd8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8852.055970670379"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(3,('<s>','The','grandstand','fell','down','</s>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696168171221,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "SPTTnIVdr4Si",
    "outputId": "d6c1325c-7202-4d98-8e75-552ef50a6773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8852.055970670379"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(3,('<s>','The','grandstand','fell','down','</s>'))**(-1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696168171222,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "_jq8qwt3r4Si",
    "outputId": "f1b95a23-867e-45b5-86be-4861f436bca1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15339.392368477242"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP(4,('<s>','The','grandstand','fell','down','</s>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696168171222,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "nteTsA_zr4Sj",
    "outputId": "d9a0acf2-d4e6-483a-e3ba-db64526c4534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15339.392368477242"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_stupid_backoff(4,('<s>','The','grandstand','fell','down','</s>'))**(-1/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEX49unXr4Sj"
   },
   "source": [
    "### Part D\n",
    "\n",
    "Print out the first ten sentences in the training set, with their perplexities to 2 decimal places, using trigrams.  Then do the\n",
    "same for the testing set.\n",
    "\n",
    "Print out the text of the sentences in a readable form, e.g., for a sentence `w`, print it out using\n",
    "\n",
    "    ' '.join(w[1:-1)\n",
    "    \n",
    "    \n",
    "Notice the perplexities of the training set are generally smaller than the testing set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696168171222,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Ia3DHJ2Nr4Sj",
    "outputId": "b1e5bf3c-a17f-465b-9137-9560e4f9db94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.76\tMuscle weakness did not improve , and the patient needed first a cane , then crutches .\n",
      "10.74\tHe replaced the flashlight where it had been stowed , got into his own car and backed it out of the garage .\n",
      "8.42\tWhen he had given the call a few moments thought , he went into the kitchen to ask Mrs. Yamata to prepare tea and sushi for the visitors , using the formal English china and the silver tea service which had been donated to the mission , then he went outside to inspect the grounds .\n",
      "10.04\t-- On the basis of a differentiability assumption in function space , it is possible to prove that , for materials having the property that the stress is given by a functional of the history of the deformation gradients , the classical theory of infinitesimal viscoelasticity is valid when the deformation has been infinitesimal for all times in the past .\n",
      "4.88\tShe said sharks have no bones and shrimp swam backward .\n",
      "9.62\tT. V. Barker , who developed the classification-angle system , was about to begin the systematic compilation of the index when he died in 1931 .\n",
      "10.32\tHe was then in man's hands .\n",
      "32.57\t4 .\n",
      "15.57\t`` Fifteen minutes , then ! !\n",
      "11.27\tThus the cocktail party would appear to be the ideal system , but there is one weakness .\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for w in training_sents[:10]:\n",
    "  sent = \" \".join(w[1:-1])\n",
    "  perplexity = np.round(PP(N=3, W=tuple(w)), 2)\n",
    "  print(f\"{perplexity}\\t{sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696168171377,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "ySSmWjBzr4Sj",
    "outputId": "6ff6c07c-3178-4043-b536-9bfb78fccf28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.79\tIt is at least as important as the more dramatic attempts to break down barriers of inequality in the South .\n",
      "1306.74\tthe car's far windshield panel turned into a silver web with a dark hole in the center .\n",
      "69.22\t`` I was just thinking how things have changed .\n",
      "1071.75\tShe smiled , and the teeth gleamed in her beautifully modeled olive face .\n",
      "438.24\t`` There isn't a chance of Myra's letting anything like that happen .\n",
      "174.63\tOn the other hand , many a pastor is so absorbed in ministering to the intimate , personal needs of individuals in his congregation that he does little or nothing to lead them into a sense of social responsibility and world mission .\n",
      "923.7\tWe live down by the Base commissary .\n",
      "484.32\tFor example , the BBB has reported it was receiving four times as many inquiries about quack devices and 10 times as many complaints compared with two years ago .\n",
      "204.82\tAs a result , life had become a kind of continuous make-ready .\n",
      "210.44\tSome of the poems express a mood of joy in a newly discovered love ; ;\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for w in testing_sents[:10]:\n",
    "  sent = \" \".join(w[1:-1])\n",
    "  perplexity = np.round(PP(N=3, W=tuple(w)), 2)\n",
    "  print(f\"{perplexity}\\t{sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrZKWrLr4Sj"
   },
   "source": [
    "### Part E\n",
    "\n",
    "Finally, we will find the perplexities of the the testing set with bigrams, trigrams, and quadrigrams.\n",
    "Complete the following template to verify that your results are consistent with the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2415,
     "status": "ok",
     "timestamp": 1696168173791,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "dPxwu7bOr4Sj",
    "outputId": "b6c69567-4890-4339-b440-d4599d899006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of the testing set for 2-grams is 387.\n",
      "The perplexity of the testing set for 3-grams is 496.\n",
      "The perplexity of the testing set for 4-grams is 957.\n"
     ]
    }
   ],
   "source": [
    "# Find all the probabilities of the sentences in the testing set, multiply them,\n",
    "# and take the $K^{th}$ root, where K is the number of tokens, excluding the <s> tokens.\n",
    "# So, K = (sum of length of sentences) - (# of sentences)\n",
    "\n",
    "# We need to take the product of many small probabilities, so use math.log and math.exp to avoid\n",
    "# underflow.\n",
    "\n",
    "# Print out the perplexity as an integer.\n",
    "\n",
    "import math\n",
    "\n",
    "# your code here\n",
    "K = sum(len(s) for s in testing_sents) - len(testing_sents)\n",
    "\n",
    "perplexity_bigrams = int(np.exp(-1/K * np.sum(\n",
    "                     np.log([P_stupid_backoff(2, tuple(testing_sents[i]))\n",
    "                     for i in range(len(testing_sents))]))))\n",
    "\n",
    "perplexity_trigrams = int(np.exp(-1/K * np.sum(\n",
    "                      np.log([P_stupid_backoff(3, tuple(testing_sents[i]))\n",
    "                      for i in range(len(testing_sents))]))))\n",
    "\n",
    "perplexity_four_grams = int(np.exp(-1/K * np.sum(\n",
    "                        np.log([P_stupid_backoff(4, tuple(testing_sents[i]))\n",
    "                        for i in range(len(testing_sents))]))))\n",
    "\n",
    "print(f\"The perplexity of the testing set for 2-grams is {perplexity_bigrams}.\")\n",
    "print(f\"The perplexity of the testing set for 3-grams is {perplexity_trigrams}.\")\n",
    "print(f\"The perplexity of the testing set for 4-grams is {perplexity_four_grams}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHxtY223r4Sk"
   },
   "source": [
    "## Problem 3: Generative N-Gram Model\n",
    "\n",
    "\n",
    "Now we will consider how to generate sentences using our N-gram model.\n",
    "\n",
    "\n",
    "The idea is fairly simple.  Suppose we have model using N=4 (quadrigrams -- the algorithm for bigrams and trigrams\n",
    "is analogous):\n",
    "\n",
    "1. To get $w_1$, choose a bigram $(\\text{\"<s>\"}, w_1)$ randomly according the probability distribution stored in\n",
    "\n",
    "$$\\text{Ngram_distribution[2][ $(\\text{\"<s>\"}, w_1)$ ]}.$$\n",
    "\n",
    "2. To get $w_2$, choose a bigram $(\\text{\"<s>\"}, w_1, w_2)$ randomly according the probability distribution calculated as\n",
    "\n",
    "$$\\text{Ngram_distribution[3][ $(\\text{\"<s>\"},w_1,w_2)$ ]}\\ /\\ \\text{Ngram_distribution[2][ $(\\text{\"<s>\"},w_1)$ ]}.$$\n",
    "\n",
    "3. To get $w_3$, choose a trigram $(\\text{\"<s>\"}, w_1, w_2, w_3)$ randomly according the probability distribution calculated as\n",
    "\n",
    "$$\\text{Ngram_distribution[4][ $(\\text{\"<s>\"},w_1,w_2, w_3)$ ]}\\ /\\ \\text{Ngram_distribution[3][ $(\\text{\"<s>\"},w_1,w_2)$ ]}.$$\n",
    "\n",
    "4. Thereafter, for a sequence $(\\text{\"<s>\"}, w_1, w_2, \\ldots, w_{i-2}, w_{i-1})$, to get $w_i$, choose a\n",
    "quadrigram $(w_{i-3}, w_{i-2}, w_{i-1}, w_i)$ randomly according the probability distribution stored in\n",
    "\n",
    "$$\\text{Ngram_distribution[4][ $(w_{i-3}, w_{i-2}, w_{i-1},w_i)$ ]}\\ /\\ \\text{Ngram_distribution[3][ $(w_{i-3}, w_{i-2},w_{i-1})$ ]}.$$\n",
    "\n",
    "5. When we generate the end of sentence marker `<\\s>` we stop.\n",
    "\n",
    "The problem is that this is difficult if we simply use the formulae given above: what we need is\n",
    "a separate probability distribution for each prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bUm3dl_r4Sk"
   },
   "source": [
    "### Part A\n",
    "\n",
    "The first step, under the assumption that we are working with N-grams for N = 1,2,3, or 4, is to build a data structure that can sample from the distribution of next tokens\n",
    "given an (N-1)-gram of left context.\n",
    "\n",
    "The best choice here is a nested default dictionary for N-grams for N = 2,3,4, the outer dictionary containing\n",
    "keys consisting of the first N-1 tokens (we'll call this the *prefix*), with the value being an inner dictionary holding a probability distribution for the last token (we'll call this *wn*).\n",
    "\n",
    "For this problem, you need to redo the construction of the list of N-grams and the distributions for\n",
    "each N, using the *entire* set of sentences, not just the testing set you used for the previous problems.\n",
    "You can easily do this by copying and pasting code from above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 4995,
     "status": "ok",
     "timestamp": 1696168178781,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "5Xcc4pAQr4Sk"
   },
   "outputs": [],
   "source": [
    "All_Ngrams = [None]*5    # first slot is empty, then Ngram[1] will hold unigrams,\n",
    "                         # Ngram[2] will hold bigrams, etc.\n",
    "\n",
    "# add <s> </s> tokens\n",
    "sentences = list(map(bracket_sentence, sentences))\n",
    "\n",
    "for n in range(1, 5):\n",
    "  All_Ngrams[n] = []\n",
    "  for s in sentences:\n",
    "    All_Ngrams[n].extend(get_Ngrams_for_sentence(n, s))\n",
    "\n",
    "# your code here\n",
    "def get_All_Ngram_distribution(N, All_Ngrams):\n",
    "  All_Ngram_dist = defaultdict(int)\n",
    "\n",
    "  for gram in All_Ngrams[N]:\n",
    "    All_Ngram_dist[gram] += 1\n",
    "\n",
    "  return All_Ngram_dist\n",
    "\n",
    "# now create for N = 1,2,3,4\n",
    "\n",
    "All_Ngram_distribution = [None]*5\n",
    "\n",
    "for n in range(1, 5):\n",
    "  All_Ngram_distribution[n] = get_All_Ngram_distribution(n, All_Ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul1kjMdcr4Sk"
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now we must build a data structure to solve the following problem: If we are working in\n",
    "an N-gram model for N = 2, 3, or 4, given a sequence of tokens\n",
    "\n",
    "$$ <s>\\ w_1\\ w_2\\ w_3\\ \\cdots w_i$$\n",
    "\n",
    "generate a sample word $w_{i+1}$ using the distribution of the N-grams of the form\n",
    "\n",
    "$$ w_{i-N+1}\\ \\cdots w_{i-1}\\ w_{i}\\  w_{i+1}.$$\n",
    "\n",
    "In other words, we use the last $N-1$ tokens of the sequence to determine a likely\n",
    "next token, given the distribution of N-grams starting with those $N-1$ tokens.\n",
    "\n",
    "The best way to do this is to build a nested dictionary. Let us call the first $N-1$ tokens\n",
    "in an N-gram the *prefix* and the last token $wn$. Then the outer dictionary\n",
    "is a `defaultdict` whose keys are the prefixes and values are an inner `defaultdict`\n",
    "whose keys are the $wn$ and whose values form a probability distribution for\n",
    "the ways that the prefix can be completed with a token $wn$.\n",
    "\n",
    "To give a simple example, suppose that in our corpus there are only the following bigrams whose\n",
    "first token is 'the':\n",
    "\n",
    "    ('the','boy'),    ('the','baby'),     ('the','baby'),    ('the','man')\n",
    "    \n",
    "Then our outer dictionary would have the prefix\n",
    "\n",
    "    ('the',)\n",
    "    \n",
    "as a key, and the inner dictionary would store the probability that each of 'boy', 'baby', and 'man'\n",
    "would follow 'the', as shown in the next code cell.\n",
    "\n",
    "Note that the prefix is an N-gram (a tuple) and $wn$ is simply a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696168178781,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "vYhDUsRFr4Sk",
    "outputId": "7b2de1b9-d0c8-4a06-8ee2-39450ee0db4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {('the',): defaultdict(<function __main__.<lambda>()>,\n",
       "                         {'boy': 0.25, 'man': 0.25, 'baby': 0.5})})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = defaultdict(lambda: None)\n",
    "\n",
    "D[('the',)] = defaultdict(lambda: 0)\n",
    "D[('the',)]['boy'] = 0.25\n",
    "D[('the',)]['man'] = 0.25\n",
    "D[('the',)]['baby'] = 0.5\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyj6Cbg5r4Sk"
   },
   "source": [
    "Your task is to complete the following template and build a nested default dictionary giving\n",
    "the probability distributions for completions for (N-1)-grams.\n",
    "\n",
    "Hint:  For each N, you must create a `defaultdict` for all N-grams, whose key\n",
    "is the prefix and whose values are an inner `defaultdict`. For each N-gram,\n",
    "you should store the probability of the N-gram prefix+wn under the key $wn$.\n",
    "Then you must normalize these probabilities so that their sum is 1.0.\n",
    "\n",
    "The end result will be that if you look up a prefix (N-1 tokens), you will\n",
    "have a probability distribution of possible $wn$ which can be used for\n",
    "the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 10671,
     "status": "ok",
     "timestamp": 1696168189449,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "qb04EL34r4Sk"
   },
   "outputs": [],
   "source": [
    "# now build a dictionary of lists of completions, with probabilities\n",
    "# For N-gram, key is prefix, of length N-1, which returns a dictionary\n",
    "# with keys that are tokens (the last token wn in the N-gram), with\n",
    "# values the number of times that N-gram (prefix),wn occurs.\n",
    "\n",
    "# N here is the length of the whole N-gram, so the prefix is of length N-1\n",
    "\n",
    "def get_Ngram_dict(N):\n",
    "  # your code here\n",
    "  nested = defaultdict(defaultdict)\n",
    "  for ngram in All_Ngram_distribution[N]:\n",
    "    inner_key = ngram[-1]\n",
    "    inner_value = All_Ngram_distribution[N].get(ngram, 0.0)\n",
    "    total = All_Ngram_distribution[N-1].get(ngram[:-1], 0)\n",
    "    inner_value = inner_value if total == 0 else inner_value / total\n",
    "    nested[ngram[:-1]].update({inner_key: inner_value})\n",
    "  return nested\n",
    "\n",
    "Ngram_nested_dict = [None]*5\n",
    "\n",
    "for n in range(2,5):\n",
    "    Ngram_nested_dict[n] = get_Ngram_dict(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1696168189449,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "1wJNWU_cr4Sk",
    "outputId": "73d384bc-6b07-4d40-f819-bfe8e9a1df8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000744"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tests: these should sum to (close to) 1.0\n",
    "\n",
    "sum(Ngram_nested_dict[2][('<s>',)].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "FX0L0TP8r4Sk",
    "outputId": "b6c5e257-290c-4298-c9f6-fb94f705cfc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999502"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Ngram_nested_dict[3][('<s>','The')].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "me_9pjtGr4Sl",
    "outputId": "b1e10dbd-3ada-47b9-f345-84cc2746cd55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Ngram_nested_dict[4][('<s>','When', 'the')].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OumVhOZUr4Sl"
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now that we have a way of sampling the next likely word, we will write\n",
    "a function which will predict the next word. You must sample from the\n",
    "probability distribution given a prefix, to choose a likely next word.\n",
    "\n",
    "Hint:  read about `numpy.random.choice`, in particular how you can set the parameter `p`\n",
    "to determine the probability of selecting a given key from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Ud4YNtnKr4Sl"
   },
   "outputs": [],
   "source": [
    "# given a prefix, randomly choose next token using the appropriate probability distribution\n",
    "\n",
    "#  len(prefix) must be 1, 2, 3, or 4\n",
    "\n",
    "def next_word(prefix):\n",
    "  # your code here\n",
    "  N = len(prefix)+1\n",
    "  choices, probas = list(zip(*Ngram_nested_dict[N][prefix].items()))\n",
    "  return str(np.random.choice(choices, p=probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "muZ8xa5Jr4Sl",
    "outputId": "58f18fd1-d242-43b0-dd07-aa005991551a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'It'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tests\n",
    "\n",
    "next_word(('<s>',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "ErLXiI-rr4Sl",
    "outputId": "e577e46f-02d2-4cde-840a-e2a2fe1ff30b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'subjects'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word(('<s>','The'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "Tsye862Kr4Sl",
    "outputId": "aeb89c8c-cb18-455a-f620-6a60461f5f9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'stood'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word(('<s>','The','man'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WM7z_7gr4Sl"
   },
   "source": [
    "### Part D\n",
    "\n",
    "Complete the following template to generate a random sentence by starting with\n",
    "the unigram `('<s>',)` and extending it by sampling until you generate the token `</s>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "UNKZwvKVr4Sl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# N is the parameter in N-gram\n",
    "\n",
    "def generate_sentence(N):\n",
    "  # your code here\n",
    "  generated = ('<s>',)\n",
    "  idx = 0\n",
    "\n",
    "  while generated[-1] != '</s>':\n",
    "    if len(generated) >= N:\n",
    "      idx += 1\n",
    "    generated += (next_word(generated[idx:]),)\n",
    "\n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696168189450,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "5aVeDcxPr4Sm",
    "outputId": "b2293316-d380-459d-a3d5-d073ea4ae643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.1 Determine if we become so '' , it , residence in the process . \n",
      "\n",
      "15.18 He went into the pool too . \n",
      "\n",
      "3.41 a middle distance often containing the major motif ; ; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tests  -- run this cell many times!\n",
    "\n",
    "\n",
    "\n",
    "w1 = generate_sentence(2)\n",
    "\n",
    "print(np.around(PP(2,w1),2), ' '.join(w1[1:-1]),'\\n')\n",
    "\n",
    "w2 = generate_sentence(3)\n",
    "\n",
    "print(np.around(PP(3,w2),2), ' '.join(w2[1:-1]),'\\n')\n",
    "\n",
    "w3 = generate_sentence(4)\n",
    "\n",
    "print(np.around(PP(4,w3),2), ' '.join(w3[1:-1]),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sffCV_Fir4Sm"
   },
   "source": [
    "### Part E\n",
    "\n",
    "Experiment with generating sentences for various values of N = 2, 3, 4. How do the perplexities compare?  Do you see a difference\n",
    "in the quality of the sentences? How well does it do with punctuation and quotes?\n",
    "\n",
    "The typical view is that for larger values of N,\n",
    "the model is just \"memorizing\" the corpus. Do you think this is true? (You might look through\n",
    "the corpus to see what relationship your generated sentences, say for N = 4, have with\n",
    "the sentences in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1696168189574,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "t-Skr606EA4u",
    "outputId": "ceae70d0-a8d6-4cf4-8ae0-4e3a735fefa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 2: 47.83 He started laughing . \n",
      "\n",
      "N = 3: 5.09 Do patriots everywhere know enough to send Lieutenant-Colonel Henry Leavenworth from Detroit as a single day to reassure me . \n",
      "\n",
      "N = 4: 1.89 The total of these three declarative statements and detailed descriptions of the formats and functions of each of these , as distinct feelings and concepts , to say the least of it . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = generate_sentence(2)\n",
    "\n",
    "print('N = 2:', np.around(PP(2,w),2), ' '.join(w[1:-1]),'\\n')\n",
    "\n",
    "w = generate_sentence(3)\n",
    "\n",
    "print('N = 3:', np.around(PP(3,w),2), ' '.join(w[1:-1]),'\\n')\n",
    "\n",
    "w = generate_sentence(4)\n",
    "\n",
    "print('N = 4:', np.around(PP(4,w),2), ' '.join(w[1:-1]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 11146,
     "status": "ok",
     "timestamp": 1696168200718,
     "user": {
      "displayName": "Alex Lavaee",
      "userId": "12456354411202670063"
     },
     "user_tz": 240
    },
    "id": "DAL7bOynEJqj",
    "outputId": "e6b0ca42-6a8d-4376-957a-fc628a0e2ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1000 generations with N = 4, there are 522 sentences that exactly match the corpus.\n"
     ]
    }
   ],
   "source": [
    "num_generations = 1000\n",
    "counts = 0\n",
    "\n",
    "# check how much the model is just \"memorizing\" the corpus for N=4\n",
    "for _ in range(num_generations):\n",
    "  w = generate_sentence(4)\n",
    "  counts += sentences.count(list(w))\n",
    "\n",
    "print(f\"In {num_generations} generations with N = 4, there are {counts}\\\n",
    " sentences that exactly match the corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nshp8WiGr4Sm"
   },
   "source": [
    "Based off of initial exploration of generation I notice that the greater the value of $N$, the greater the generation length typically is. This is interesting because perpexlity decreases as the length of the generated output increases. After running multiple generations of $N=2, 3, 4$ I like the quality of $N=2$ the best because it generates shorter sentences that make more sense. Probablistically, it makes sense that the bigrams would make more sense because they typically generate less tokens making it easier to generate short text that makes more sense and are able to sample from a greater space since they are the most prevalent n-gram greater than $1$. As dataset size increases, however, I believe we would see larger $N$ being better since they will naturally have more examples. Punctuation greatly varies between generations with some generations being reasonable while others having extraneous punctuation such as \"!!, :, ????, etc.\" After running the above code to check how much the model is just \"memorizing\" the corpus for $1000$ generations, I do think it may be memorizing since a good portion of the sentences are exact copies of the sentences in the corpus."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
